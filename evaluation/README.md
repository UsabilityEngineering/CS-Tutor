# Usability Evaluation

## Heuristic Evaluation
SCALE: (1) Very Bad to (5) Very Good

Our initial heuristic evaluation returned a lot of useful information. Users found the visibility of the system status about a 4. It was mentioned that outcomes were relatively predictable, and the system provided enough feedback while navigating to prevent confusion.
On "Match Between System and Real World," users rated our prototype between a 3 and a 4, citing the calendar as a familiar element, yet mentioning that specific elements of formatting were unfamiliar. The tags were said to be a good system for conducting searches by one user, which was contradicted by another in the "User Control and Freedom" section.
"User Control and Freedom" also sat somewhere around a 3 and a 4, with two users disagreeing over the usefulness of the tag system. Ease of being able to contact tutors is a plus in this category.
The calendar section is a familiar design device, and therefore got a 4 from both users in "Consistency and Standards." One user appreciated that the calendar view stayed put even while navigating between days, for extra consistency in design.
"Error prevention" got a 3 from both users, as there was no indication as to how the program would actually handle errors. It was mentioned that more feedback regarding user decisions and errors would be useful in this area, specifically for when appointments are canceled.
"Recognition Rather than Recall" scored a 4 from both users, as the sidebar layout prevented users from having to use memory too often. This means that there was little swapping between full pages.
"Flexibility and Efficiency of Use" scored between a 2 and 3 from users, with more comments focusing on the tags system. One user felt that this system would work well for finding specific tutors, but wished for "permanent filters" of some sort. More feedback might be necessary on this topic. Another user mentioned that tags are redundant when one knows what they are looking for.
"Aesthetic and Minimalist Design" ended up scoring a 4, as the design was kept simplistic. No extra information cluttered the design, and one user mentioned that it did not "diminish visibility of key functionality."
The areas dealing with "helping users recognize, diagnose and recover from errors" scored some of the lowest points, receiving a 2. There were no demonstrated errors, nor demonstrations of the recovery process from these errors.
"Help and Documentation" also received a 2, as there were no buttons leading users to help.

## Cognitive Walkthrough
Users tended to pick the student when deciding between personas to write cognitive walkthroughs on. Users understood Ortegga, the student, as someone who needed help through the tutoring system to relieve stress and better her performance.
When assessing the interface, one user was quick to utilize the search bar as the first step in their cognitive walkthrough. This was echoed by three other users, with two immediately understanding the "filter" system in their assessment.
The first user understood the right-most sidebar as a section that gives more concrete info on the selected calendar day, and the tutors associated with that day. This user also mentions that the logistics of each tutor's sessions are available.
The first user felt confusion over the plus button in the upper right corner, intended for adding new tutoring sessions to the specific day. This feature is intended only for faculty or tutors, and was not intended to be part of the student experience. This user mentioned that a label might help to disambiguate the function. This user confused the "add a tutoring session" feature for a way to create an appointment with a tutor, when they should have clicked on "contact" on any of the tutor's cards.
The second user was more vague on how they went about certain tasks, explaining them from a high level: "Ortega decides to schedule a 2 hour tutoring session," rather than something like "Ortega clicks on the X button."
The third user easily navigated the calendar view, and successfully clicked on the "Contact" button to make contact with the tutor, thus completing the task. This user also mentioned that they received the room number and time listed in the card.
The fourth user had a similar experience, although they did not click the "Contact" button, and rather decided to show up at the same time the tutor would be there. This might indicate that each tutoring session should mention whether or not it is a "drop-in" or "scheduled-only" type of session.

## Usability Protocol
Task 1: The first task was prompting a user to search and see what days Dave Merchant was tutoring. This was intended to familiarize users with the system, and to give them a sense of what the system was intended to be used for. This specifically points users in the direction of the search bar, and attempts to see if they are familiar with the tags system right off the bat. This reveals the "consistency and standards" component of UX, as this system attempts to utilize various established standards in hopes of users not having to ask for help, or to consult documentation sections.
Task 2: This second task prompts users to assume the role of faculty, and create a tutoring session on the 21st of March. This task was specifically created to see if the plus button in the top right of the screen was obvious enough to faculty, as our previous heuristic and cognitive evaluations gave us the indication that the plus button might be a little too vague. This button's original intention was to create tutoring sessions on specific days. An element of user control could be gauged from this, as feeling lost in the process of this task would lead to the user feeling helpless and upset. Part of our original goal was to shorten the length of the training process for using this system, so understanding the ease of performing this task was important.
Task 3: This final task involves deleting a tutoring session on a specific date and time as a faculty member. We discussed the visibility of the "hamburger menu" that allowed users to manipulate entries in the right-most sidebar, and felt that this test would allow us to see whether or not users intuitively could find out how to manage entries. (This hamburger menu contains the "delete" and "edit" features, as well as an option to open the payroll list to a specific name.) There is also an element of standards revealed from this task, as it allows us to see what users immediately expect from a hamburger menu placed so closely to a name.
Wrap-Up Questions: Our concluding questions were meant to get a user's general thoughts on the prototype. We prompted them about what they liked most, disliked most, as well as features they'd like to see. We also asked about other thoughts or comments they might have on the system, to aid in our ideation and refinement process.
The "Think-Aloud" method was chosen for our evaluations, as we needed to understand if the user's mental model matched with our own as designers. Efficiency testing might be useful in later stages of refinement, but for the initial user testing, getting the deep thoughts of participants was important to us so that we could fix ambiguous buttons and layouts.
We chose a formative evaluation focus, as there were elements of our existing design that we knew needed to be improved before any kind of release. We focused specifically on areas that we thought users might find ambiguity with, and tested them hard to see if users could overcome our initial concerns. This data would be later used to redesign key areas of the application.

## Mock-Data Interpretation
SCALE: (1) Very Bad to (5) Very Good
SAMPLE SIZE: 5 Users
We determined that the search bar was one of the first thoughts many users had when performing the first task. Task 1 really showed that users were able to not only understand the tri-column layout intuitively, but also parse the tutoring session list and find their destination without thinking too hard about it. While most users did not have an issue with this task, one was confused by the "Tutor List" in the left-most sidebar, a feature that was (much like the plus button in the top right of the page,) intended for faculty use only. We concluded that changing the term "tutor list" to "payroll" might be the best way forward, as this feature had a very limited intended usage. Ease of performing the first task was rated a 4 by three users and a 5 by two users.
The second task revealed some useful information. A majority of the users were easily able to find the plus button in the top right of the screen for adding new tutoring sessions without any issues. However, a certain small number of users still did encounter confusion when interacting with this button. Feedback was given that this button should have a label, backing up the initial concerns we had. This change shouldn't be hard to make, and solely compromises on the minimalistic design rather than anything functional. Ease of performing this task was rated a 2 by a single user, 5 by three users and a 4 by a single user. The lowest score came from the user's perception that other people might have difficulty with the task, but made a note that they had little difficulty with it because of their previous experiences.
The third task surprised us, as a majority of the users found the delete option hidden within a hamburger menu. This task was much quicker than we had anticipated, and only a single user had serious problems trying to find the delete button. This user eventually found it, but was looking elsewhere in the sidebar for a feature to delete tutoring sessions. This user rated the task at a 4, while all other users rated the task at a 5, making the deletion process one of the highest rating tasks we tested for.
User's overall assessments of our design were primarily positive. One user suggested using "Apple Calendars" style blocks for the weekly view, so that users could see which tutors were available in a clearer way. Another user suggested we remove the "common tags" section, as it was a little confusing, and they thought it was closer to a menu bar. Another user enjoyed the way that search filters highlight specific cells, and recommended that we fix the plus button. Another user, (who had previously been a tutor,) enjoyed the system and said that they would definitely use it. The final user felt that the search was a positive feature, but that the right side was very cluttered. This may be because the prototype does not feature collapsable cards. This reminded us that a lot of our issues came from the inability of the prototype to reflect the exact final experience.
